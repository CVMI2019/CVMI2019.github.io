<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta content="IE=edge" http-equiv="X-UA-Compatible">
  <meta content="width=device-width,initial-scale=1" name="viewport">
  <meta content="description" name="description">
  <meta name="google" content="notranslate" />
  <meta content="Mashup templates have been developped by Orson.io team" name="author">

  <!-- Disable tap highlight on IE -->
  <meta name="msapplication-tap-highlight" content="no">

  <link href="./assets/apple-icon-180x180.png" rel="apple-touch-icon">
  <link href="./assets/favicon.ico" rel="icon">



  <title>CVMI</title>

<link href="./main.82cfd66e.css" rel="stylesheet"></head>

<body>

 <!-- Add your content of header -->
<header class="">
  <div class="navbar navbar-default visible-xs">
    <button type="button" class="navbar-toggle collapsed">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a href="./index.html" class="navbar-brand"><strong>CVMI</strong></a>
  </div>

  <nav class="sidebar">
    <div class="navbar-collapse" id="navbar-collapse">
      <div class="site-header hidden-xs">
          <!--<h3><strong>CVMI</strong></h3>-->
          <img class="img-responsive" alt="" src="./assets/images/img-001.png" height:200 width:200>
      </div>
      <style type="text/css">
        ul{
          list-style: none;
          padding:0;
          overflow:hidden;
          display:table;
          height:auto;
          margin:0 auto;
        }
        ul li{
          float: left;
        }
        ul a{
          color: #fff;
          width: 200px;
          padding: 10px;
          background: #bebebe;
          text-decoration: none;
          text-align: center;
          font-weight: bold;
          display: block;
        }
        ul li ul{
          display: none;
        }
        ul li ul li{
          float: none;
          list-style: none;
          margin-top: 2px;
        }
        ul li ul li a:hover{
          background: #06f;
        }
        ul li:hover ul{
          display: block;
        }
        body {
          color: black;
          background-color:floralwhite}
      </style>
      <ul class="nav">
         <li><a href="./new.html" title=""><I><font size="4" color="red"><strong>New</strong></font></I></a></li>
        <li><a href="./index.html" title=""><font size="4"><strong>Welcome</strong></font></a></li>
        <li><a href="./callForPaper.html" title=""><font size="4"><strong>Call for Papers</strong></font></a></li>
        <li><a href="./organizers.html" title=""><font size="4"><strong>Organizers</strong></font></a></li>
        <li><a href="./comittee.html" title=""><font size="4"><strong>Program Comittee</strong></font></a></li>
        <li><a href="./speakers.html" title=""><font size="4"><strong>Invited Speakers & Panelists</strong></font></a></li>
        <li><a href="./dates.html" title=""><font size="4"><strong>Important Dates</strong></font></a></li>
        <li><a href="./submission.html" title=""><font size="4"><strong>Submission</strong></font></a></li>
         <li><a href="./accepted.html" title=""><font size="4"><strong>Accepted Papers</strong></font></a></li>
        <li><a href="./program.html" title=""><font size="4"><strong>Program</strong></font></a></li>
        <li><a href="./venue.html" title=""><font size="4"><strong>Venue</strong></font></a></li>
        <li><a href="./contact.html" title=""><font size="4"><strong>Contact</strong></font></a></li>
        <li><a href="./pastcvmi.html" title=""><font size="4"><strong>Past CVMIs</strong></font></a></li>
      </ul>
    </div>
  </nav>
</header>
<main class="" id="main-collapse">


  <div class="hero-full-wrapper">
    <div class="grid">
    <div class="gutter-sizer"></div>
      <div class="grid-sizer"></div>

        <img class="img-responsive" alt="" src="./assets/images/img-0001.png">
        <style>
        .grid img{
           -moz-box-shadow:6px 6px 7px #000;
           -webkit-box-shadow:6px 6px 7px #000;
           box-shadow:6px 6px 7px #000;
           filter:progid:DXImageTransform.Microsoft.Shadow(Strength=6,Direction=135,Color='#000000');
        }
        </style>
        <br />
        <h2 id="welcome">Invited Speakers & Panelists</h2>
<hr> 

      <font size="4">
        
        <p>  <strong>Title:</strong> TBD</p>
        <!--<p>  <strong> Start Time:</strong>  8:45 AM   </p>-->
        <p> <strong>Speaker:</strong> Dr. Anne Bang, Director, Cell Biology, Conrad Prebys Center for Chemical Genomics at Sanford Burnham Medical Research Institute </p>
        
        <p><center>
<img class="img-responsive" alt="" src="./assets/images/Anne-Bang.jpg"  width="300" height="700">
</center></p>
        <!--        
        <p>
         <strong> Abstract:</strong> 
          How is it possible that we still have nothing to offer patients with devastating incurable diseases like ALS, autism, Alzheimer’s disease, schizophrenia and Parkinson’s disease even though we have known about these diseases for over a century in some cases? Do the advances in computer vision have anything to offer to help?
        </p>   
        <p>
          In this talk, we will introduce the challenges and opportunities in the area of neurodegenerative diseases, emphasizing some of the obstacles where computer vision can help. To address some of the challenges, we built automated microscopes and developed patient-derived stem cell models of human neurodegenerative diseases. In addition, we developed an array of several hundred biosensors to expand the feature set from images. These methods generate large highly multidimensional imaging datasets amenable to analysis with supervised and unsupervised machine learning, which we are using to better understand the causes of disease, to find targets that can be pursued therapeutically, and to investigate the structure and nature of patient populations, which could lead to stratifications that could help make clinical trials more successful.
          
          </p> 
        -->          
<p> <strong>Bio: </strong>  Dr. Anne Bang is an experienced cell biologist and stem cell expert who leads efforts at the Sanford Burnham Prebys Center to develop patient cell specific and human induced pluripotent stem cell (hiPSC)-based disease models for drug screening and target identification. Anne is a principal investigator for the National Institute of Mental Health (NIMH) National Cooperative Reprogrammed Cell Research Groups consortium, and also receives research support from rare disease foundations and pharma sponsored collaborations.
 </p>   
 <p>
  Dr. Bang was previously at ViaCyte Inc. (formerly Novocell Inc.), since 2005, where as Director of Stem Cell Research she oversaw a group of scientists working to develop human embryonic stem cells as a replenishable source of pancreatic cells for the treatment of diabetes. She received her Ph.D. in Biology from the University of California in San Diego, and was a post-doctoral fellow and a Senior Research Scientist in the Neurobiology Laboratory at The Salk Institute for Biological Studies, in La Jolla, CA.   
</p>
      
   
<hr> 

       <p>  <strong>Title:</strong>  The ImageJ Ecosystem: An Open and Extensible Platform for Biomedical Image Analysis </p>
      <!--<p>  <strong> Start Time:</strong>  9:45 AM   </p>-->
        <p> <strong>Speaker:</strong> Professor Kevin Eliceiri, Director, Laboratory for Optical and Computational Instrumentation, University of Wisconsin–Madison </p>
        
      <p><center>
<img class="img-responsive" alt="" src="./assets/images/eliceiri_kevin.jpg" width="200" height="500" >
</center></p>
     <!--
        <p>
         <strong> Abstract:</strong>  The beginning of the 21st century has seen a great renaissance in light microscopy in neuroscience, with new instruments and brain clearing and staining methods capable of generating complete datasets for the mouse brain at up to a submicron brainwide resolution. Here I will review the main pros and cons of the different types of the microscopy instrumentation and methods, and I will also describe our computational pipeline and toolchain software called Headlight for reconstruction, anatomical registration and computational analyses of the whole brain datasets. Finally, I will give examples of scientific applications from my lab at CSHL in systematic atlasing of cell-type distribution and morphology as well as from a biotech start-up Certerra focused on commercializing these methods for CNS drug screening.
          </p>
        -->
 <p>  <strong>Bio: </strong> 
  Dr. Kevin Eliceiri is the Walter H. Helmerich Research Chair and Associate Professor of Medical Physics and Biomedical Engineering at the University of Wisconsin at Madison. He is an Investigator in the Morgridge Institute for Research and member of the Carbone Cancer Center and McPherson Eye Research Institute.  He is director of the Laboratory for Optical and Computational Instrumentation, a biophotonics laboratory dedicated to the development and application of optical and computational technologies for cell studies.  The Eliceiri lab is a lead developer in several open source imaging packages including FIJI and ImageJ. His instrumentation efforts involve novel forms of polarization, laser scanning and multiscale imaging.  Dr. Eliceiri has authored more than 180 scientific papers on various aspects of optical imaging, image analysis, cancer and live cell imaging. <font size="4">
   </p>  
   
 
<hr> 

      <p>  <strong>Title:</strong> Survey of new methods for complex image-based screens </p>
      <!--<p>  <strong> Start Time:</strong>  11:30 AM   </p>-->
      <p> <strong>Speaker:</strong> Allen Goodman, Director, MA Program in Economics, Wayne State University </p>
   
<p><center>
<img class="img-responsive" alt="" src="./assets/images/ag-areuea-recep.jpg" width="250" height="650">
</center></p>
      
<p>  <strong>Bio: </strong> 
Allen Goodman is a gifted software engineer, recognized for writing pioneering web and mobile applications. He was a founding engineer and Director of Research of Simple, a highly successful customer-oriented online bank startup, where he co-wrote their critically acclaimed mobile and web applications. Then, as a senior software engineer for Chef—the leading software automation company—he co-wrote Chef Analytics, a real-time message broker for cloud computing. His technical expertise includes cross-platform proficiency, fluency in general-purpose and scientific programming languages, and expert knowledge of popular tools, methodologies, and best practices. Goodman decided to apply his software engineering talents to biomedicine and joined the Carpenter laboratory in August 2015, where he has dramatically reshaped CellProfiler, and is leading the group’s efforts in developing new bioimage analysis tools based on deep learning methods. He was also recently named an Imaging Software Fellow, an award by the Chan Zuckerberg Initiative to support funding of open-source software efforts to improve image analysis and visualization in biomedicine.
  <font size="4">
</p>  

<hr>


    <p>  <strong>Title:</strong> TBD </p>
    <!--<p>  <strong> Start Time:</strong>  11:30 AM   </p>-->
    <p> <strong>Speaker:</strong> Dr. Santiago Miriuka  </p>
<p><center>
<img class="img-responsive" alt="" src="./assets/images/Santiago Miriuka.jpg" width="250" height="650">
</center></p>
      
<p>  <strong>Bio: </strong> 
  TBH<font size="4">
</p>   
             
<hr>
<p>  <strong>Title:</strong> What concussions do to brain cells: A Deep Look</p>
<!--<p>  <strong> Start Time:</strong>  11:30 AM   </p>-->
<p> <strong>Speaker:</strong> Professor Badri Roysam, Chair of Electrical and Computer Engineering, University of Houston </p> 

<p><center>
<img class="img-responsive" alt="" src="./assets/images/roysam.jpg" width="250" height="600">
</center></p>
      
<p>  <strong>Bio: </strong> 
  Badri Roysam (Fellow IEEE, AIMBE) is the Hugh Roy and Lillie Cranz Cullen University Professor, and Chairman of the Electrical and Computer Engineering Department at the University of Houston (2010 – present). From 1989 to 2010, he was a Professor at Rensselaer Polytechnic Institute in Troy, New York, USA, where he directed the Rensselaer unit of the NSF Engineering Research (ERC) Center for Subsurface Sensing and Imaging Systems (CenSSIS ERC), and co-directed the Rensselaer Center for Open Source Software (RCOS) that was funded by a major alumnus gift. He received the Doctor of Science degree from Washington University, St. Louis, USA, in 1989. Earlier, he received his Bachelor’s degree in Electronics from the Indian Institute of Technology, Madras, India in 1984.
Badri’s research is on the applications of multi-dimensional signal processing, machine learning, big-data bioinformatics, high-performance computing to problems in fundamental and clinical biomedicine. He collaborates with a diverse group of biologists, physicians, and imaging researchers. His work focuses on automated analysis of 2D/3D/4D/5D microscopy images from diverse applications including cancer immunotherapy, traumatic brain injury, retinal diseases, neural implants, learning and memory impairments, binge alcohol, tumor mapping, stem-cell biology, stroke research, and neurodegenerative diseases.<font size="4">
</p>     
        
            
 <hr>
 <!--       
<p><center>
<img class="img-responsive" alt="" src="./assets/images/Michelle Freund.png" width="200" height="650">
</center></p>
      
<p>Dr. Michelle Freund is Scientific Program Coordinator in the Office of Technology Development and Coordination at the National Institute of Mental Health, NIH, Bethesda, MD. As a program officer, she manages a research portfolio of grants that are focused on the development of novel tools and technologies important for the advancement of basic and translational neuroscience. 
  Michelle serves as the Director for the NIH NeuroBioBank, a network of six brain and tissue repositories that provide post-mortem human brain samples for research. She is an active member of several trans-NIH interdisciplinary teams such as the NIH BRAIN Initiative and the Blueprint for Neuroscience. As co-lead on a BRAIN Initiative team, she provides guidance and oversight for the Cells and Circuits focus area outlined in the BRAIN 2025 report. Michelle received a B.A. from the University of California, San Diego in mammalian physiology and a Ph.D. in Neuroscience from Hahnemann University in Philadelphia. 
  Before joining NIH in 2007, she studied the role of monoamine neurotransmitters in the actions of antidepressant drugs and the interactions of stress and drug addiction.<font size="4">
  </p>   

  <hr>
      
   <p><center>
<img class="img-responsive" alt="" src="./assets/images/Daniel Hoeppner.png"  width="200" height="500">
</center></p>
      
    <p>  Dr. Daniel Hoeppner is an Associate Director of Neuroscience at Astellas Research Institute of America (ARIA), in San Diego CA. 
      He manages a diverse team of scientists focused on identifying new therapeutic interventions for patients suffering with psychiatric illness. 
      His team applies the tools of human genetics, next-generation sequencing, human iPSC (stem cell) technology, mouse models, and automated microscopy to identify and validate novel targets for intervention.  
      Prior to Astellas, Dr. Hoeppner was an investigator at the Lieber Institute for Brain Development (Johns Hopkins, Baltimore MD), a Staff Scientist at the NIH-NINDS (Bethesda MD), and a graduate student of genetics at Cold Spring Harbor Laboratory (Long Island, NY).  

    </p> 


 <hr>  
<p><center>
<img class="img-responsive" alt="" src="./assets/images/jieyang.jpg"  width="200" height="500">
</center></p>
      
    <p>  Dr. Jie Yang is a Program Director in the Division of Information and Intelligent Systems (IIS) at the National Science Foundation (NSF).
      He is the leader of the Robust Intelligence Cluster and oversees computer vision research. He has also been involved in many other crosscutting programs. Before joining NSF, he was a faculty member in the School of Computer Science at Carnegie Mellon University, where he worked on multimodal/multimedia, computer vision, pattern recognition, robotics, and automatic control. 
      He was an Advisory Board member of the ACM International Conference on Multimodal Interfaces (2003-2015). He also served as Program Co-chair (2002) and General Co-chair (2006 and 2010) for ACM International Conference on Multimodal Interfaces, as well as a Program Co-chair (2010) for ACM Multimedia. 
      He served as a General Co-chair (2014) for the IEEE International Conference on Multimedia & Expo. He served as an Associate Editor for the IEEE Transaction on Multimedia (2004-2008).  He is an Associate Editor for the Machine Vision Applications journal.
      He also served as Area Chair and Program Committee member for multimodal/multimedia, computer vision, and pattern recognition conferences. He is a fellow of IEEE.<font size="4">
      
    </p> 
  
  

   
   
   
   
   
   
   
   
   
   
      
      <hr> 
       <p>  <strong>Title:</strong>  Assessment of intra-tumor heterogeneity and evolutionary trajectories in cancer </p>
      <p>  <strong> Start Time:</strong>  13:30 PM   </p>
        <p> <strong>Speaker:</strong> Dr. Subhajyoti De, Rutgers, the State University of New Jersey and Rutgers Cancer Institute </p>
        <p><center>
        <img class="img-responsive" alt="" src="./assets/images/desubho2012.jpg" width="200" height="500" >
</center></p> 
        
        
        <p> <strong> Abstract:</strong> 
           Nuclei segmentation plays an important role in digital pathology image analysis as the accurate separation of nuclei is crucial for cancer diagnosis and other clinical analysis. Current learning-based methods in nuclei segmentation have certain limitations in lowering localization accuracy. We develop FullNet, a full resolution convolutional neural network that achieves good performance in nuclei segmentation. Using annotated histopathological images, we show the effectiveness of this approach in nuclei segmentation and compare it to other state-of-the-art methods. We then describe our initiatives to integrate histopathological imaging and genomic data to inform about intra-tumor heterogeneity and evolutionary trajectories in cancer. Analyzing histopathological images for 55 BRCA1-associated breast tumors, we assess the status of BRCA1, PTEN, and p53 mutations at the single cell level. We then use computational methods to predict the relative temporal order of somatic events, on the basis of the frequency of cells with single or combined alterations. Although there is no obligatory order of events, we find that loss of PTEN is the most common first event and is associated with basal-like subtype, whereas in the majority of luminal tumors, mutation of TP53 occurs first and mutant PIK3CA is rarely detected. We also observe intratumor heterogeneity for the loss of wild-type BRCA1 and increased cell proliferation and centrosome amplification in the normal breast epithelium of BRCA1 mutation carriers. Our results have important implications for the design of chemopreventive and therapeutic interventions in this high-risk patient population.
          </p> 
        <p>  <strong>Bio: </strong> 
          Dr. Subhajyoti De is an Assistant Professor of Pathology and Laboratory Medicine at Rutgers, the State University of New Jersey and a member of Rutgers Cancer Institute. Previously, he completed his PhD at the University of Cambridge, UK and postdoctoral work at Harvard University. His research group develops and applies genomics, systems biology, and computational modeling approaches to cancer. 
         </p> 
        
      <hr> 
        
       <p>  <strong>Title:</strong> Image Analysis Methods for Measuring the Micro-Environment of Single Cells Within Three-Dimensional Multicellular Spheroids: Optimization for Breakthroughs in Drug Discovery.</p> 
        <p>  <strong> Start Time:</strong>  14:00 PM   </p> 
        <p> <strong>Speaker:</strong> Dr. Ty Voss, Voss Imaging Informatics (LLC)</p>
                    <p><center>
<img class="img-responsive" alt="" src="./assets/images/Ty Voss.jpg" width="200" height="500" >
</center></p>  
        
        <p> <strong> Abstract:</strong> 
         The natural in vivo three-dimensional (3D) organization of complex tissues allows individual cells and collections of localized cell-types to signal and behave in ways that may not be possible when those cells are grown in mono-layer tissue culture. These 3D micro-environments are important for understanding diverse disease states including cancer, chronic wound healing, auto-immune diseases, and neuro-degenerative syndromes. Accordingly, the pharmaceutical research industry has recently committed significant resources towards measuring the behavior of multicellular spheroids/organoids in more high-throughput modalities for screening purposes. However, the majority of these published high-throughput imaging studies have only measured ‘whole spheroid-level responses’ and have lacked single-cell level information. In contrast, several academic studies have shown that single-cell level 3D imaging measurements can be obtained from organoid samples, but the image acquisition and analysis methods do not have sufficient throughput for screening purposes. In this presentation, we will describe our recent efforts to optimize sample preparation, high-throughput image acquisition, and parallelized automated 3D image analysis. This convergence of optimized methods provides single-cell level data from large numbers of spheroid samples, which will be essential for ongoing drug discovery screens. 
        </p>
        
        <p> <strong>Bio: </strong> 
          Ty C. Voss received a BSc degree in biochemistry from Oklahoma State University in 1994 and then studied for his molecular biology doctoral degree at Tulane University. During this period, he began quantifying and computationally modeling the effects of hormonal regulation on transcription at the single cell level. He extended these studies and developed more advanced automated microscopy approaches during two fellowships, first at the University of Virginia and then at the NIH Campus in Bethesda MD. In 2009, He began collaborating with NCI Sr. Research Faculty to establish the NCI High-Throughput Imaging Facility (HiTIF). He served as the HiTIF head for four years, developing and executing automated microscopy assays, along with siRNA screening campaigns. In 2013, He founded a bio-informatics business, Voss Imaging Informatics (LLC), that provides consulting services and customized analytical software solutions for multiple government, academic, and commercial research clients. These contracted consulting projects are presently ongoing (2018). Dr. Voss also acted as Senior Applications Scientist for North America with the PerkinElmer Cellular Imaging and Analysis Team during 2014-2016.
       </p> 
        
        
        <hr>
        
      <p>  <strong>Title:</strong>   Life and death decisions- classification, characterization and predictions of death in neuronal models of neurodegenerative disease</p>
       <p>  <strong> Start Time:</strong>  16:30 PM   </p>
        <p> <strong>Speaker:</strong> Dr. Jeremy Linsley, Gladstone Institutes and the University of California, San Francisco </p>
            <p><center>
<img class="img-responsive" alt="" src="./assets/images/JeremyLinsley.jpeg" width="200" height="500" >
</center></p>  
        
         <p> <strong> Abstract:</strong> 
           Understanding the cellular changes that destine a neuron to live or to die is a fundamental challenge to understanding neurodegenerative disease. We use robotic microscopy, an imaging platform that uses automated identification and tracking of millions of individual neurons in culture over time, to quantitatively relate intermediate changes within a neuron to its fate. Interpreting changes within degenerating neurons is complicated both by the task of analyzing dense and complex microscopy images, as well as by the complication of analyzing progressive and often sporadic diseases. Using convolutional and recurrent neural networks, we quantify, interpret, and predict features in human patient derived neurons. These in silico methods reliably predict standard conventional cell-biological techniques, facilitate measurements that would be problematic or impossible to acquire using conventional methods, and outperform human manual curation. By surveying neurons derived from patients across neurodegenerative disease, we are developing algorithms for classifying unhealthy and diseased neurons across a variety of neurodegenerative diseases. Additionally, we are able to reliably predict the life or death of a neuron prior to death, focusing our window for understanding the mechanisms for these progressive diseases. We believe the use of these technologies will enhance our understanding of the pathology and physiology underlying neurodegenerative diseases with the goal of creating new therapies and cures for these devastating diseases.
         </p>
         <p>  <strong>Bio: </strong> 
        Dr. Jeremy Linsley is a postdoctoral fellow in Steve Finkbeiner’s lab in the Center for Systems and Therapeutics at the Gladstone Institutes and the University of California, San Francisco. Jeremy studies neurodegenerative disease models using four-dimensional imaging, novel fluorescent biosensors, and deep learning analysis. He combines artificial intelligence approaches with a fully automated robotic microscope developed by the Finkbeiner laboratory that can track individual cells for hours, days, or even months. Using these tools, he is developing cutting-edge technologies to detect, predict, and analyze a range neurodegenerative diseases. By shedding light on underlying pathology and physiology, Linsley’s work aims to create new therapies and cures for these devastating diseases. Linsley earned a PhD in molecular and cellular biology from the University of Michigan, where he studied a family of adaptor-like proteins. He explained the mechanism of action for one of the proteins in skeletal muscle and discovered that a mutation in one of the proteins was the basis for the debilitating Native American myopathy disease.
         </p> 
        
        
    <hr>
                <p>  <strong>Title:</strong> Efficient and Scalable Tools for Large Scale Microscopy Image Analysis</p> 
         <p>  <strong> Start Time:</strong>  17:00 PM   </p>
         <p> <strong>Speaker:</strong> Dr. Erhan Bas, Janelia Research Campus of HHMI </p>
                    <p><center>
<img class="img-responsive" alt="" src="./assets/images/Erhan Bas.png" width="200" height="500" >
</center></p>  
        
        <p> <strong> Abstract:</strong> With the advances in hardware and computational tools, large-scale high resolution volumetric imaging of whole systems is possible. Analysis of large volumes requires scalable segmentation algorithms and visualization platforms to efficiently stream through data and utilize user feedback. We developed an interactive segmentation and visualization framework for proofreading of large (tens of TBs) sparse volumetric datasets that aims to minimize user interaction with directed segmentation workflows. 
          Developed tools enabled the analysis and proofread of more than 500TBs of volumetric data and resulted in the largest axonal reconstruction database available(<a href="https://http://ml-neuronbrowser.janelia.org/">https:http://ml-neuronbrowser.janelia.org/</a>).
          </p>
            
        <p> <strong>Bio: </strong> 
          Erhan Bas received his PhD in Electrical and Computer Engineering from Northeastern University, Boston in 2011. He joined the Mouselight team at Janelia Research Campus (JRC) of HHMI as a computer scientist in 2015. At JRC, he is interested in large scale image analysis techniques for neuronal morphology analysis. Before joining to JRC, he was with the computer vision lab at GE Global Research in Niskayuna, NY, where he led a team of material and computer scientists working on industrial inspection technologies and he was an adjunct professor at Rensselaer Polytechnic University (RPI), Troy, NY where he taught Biological Image Analysis course. His general research interests include machine vision and statistical pattern recognition with various applications in biomedical and industrial image processing. He is one of the five Diadem challenge finalists and he serves as a member of IEEE Bio Imaging and Signal Processing Technical Committee, where he has been serving as an organizing committee member and area chair of ICIP 2015 and ISBI 2015&2018.
         </p> 
    <hr>

        -->
      
    </div>

</main>

<script>
document.addEventListener("DOMContentLoaded", function (event) {
  navbarToggleSidebar();
  navActivePage();
});
</script>

<!-- Google Analytics: change UA-XXXXX-X to be your site's ID

<script>
  (function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
      (i[r].q = i[r].q || []).push(arguments)
    }, i[r].l = 1 * new Date(); a = s.createElement(o),
      m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
  })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
  ga('create', 'UA-XXXXX-X', 'auto');
  ga('send', 'pageview');
</script>

--> <script type="text/javascript" src="./main.85741bff.js"></script></body>

</html>
